{
  "8": {
    "inputs": {
      "samples": [
        "65",
        0
      ],
      "vae": [
        "10",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "10": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "12": {
    "inputs": {
      "unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "61": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "65": {
    "inputs": {
      "seed": 65,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "124",
        0
      ],
      "positive": [
        "68",
        0
      ],
      "negative": [
        "69",
        0
      ],
      "latent_image": [
        "118",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "67": {
    "inputs": {
      "shift": 3.19,
      "model": [
        "12",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "68": {
    "inputs": {
      "prompt": [
        "120",
        0
      ],
      "clip": [
        "61",
        0
      ],
      "vae": [
        "10",
        0
      ],
      "image1": [
        "122",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus (Positive)"
    }
  },
  "69": {
    "inputs": {
      "prompt": "unnatural skin, oversharpened, plastic texture, harsh lighting, blemishes\n",
      "clip": [
        "61",
        0
      ],
      "vae": [
        "10",
        0
      ],
      "image1": [
        "122",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "TextEncodeQwenImageEditPlus"
    }
  },
  "82": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "117": {
    "inputs": {
      "image": "Screenshot 2025-12-22 235415.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "MASTER_IMAGE"
    }
  },
  "118": {
    "inputs": {
      "width": [
        "119",
        0
      ],
      "height": [
        "119",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "119": {
    "inputs": {
      "image": [
        "122",
        0
      ]
    },
    "class_type": "Get Image Size",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "120": {
    "inputs": {
      "move_horizontal": 0,
      "move_vertical": 0,
      "move_forward": 0,
      "rotate": 45,
      "view_top_down": true,
      "view_wide_angle": true,
      "view_close_up": false,
      "view_bottom_up": false
    },
    "class_type": "CameraControlPromptNode",
    "_meta": {
      "title": "MASTER_PERSPECTIVES"
    }
  },
  "121": {
    "inputs": {
      "PreviewTextNode_0": "",
      "text": [
        "120",
        0
      ]
    },
    "class_type": "PreviewTextNode",
    "_meta": {
      "title": "Preview Text Node"
    }
  },
  "122": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1,
      "image": [
        "117",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "123": {
    "inputs": {
      "lora_name": "henoch/95E5B4BDE6A2 (1).safetensors",
      "strength_model": 1,
      "model": [
        "67",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LORA_LOADER_01"
    }
  },
  "124": {
    "inputs": {
      "lora_name": "Qwen-Image-Edit-2509-Lightning-4steps-V1.0-bf16.safetensors",
      "strength_model": 1,
      "model": [
        "123",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LORA_LOADER_02"
    }
  }
}