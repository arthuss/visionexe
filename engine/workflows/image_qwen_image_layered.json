{
  "60": {
    "inputs": {
      "filename_prefix": [
        "133",
        0
      ],
      "images": [
        "126",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "74": {
    "inputs": {
      "image": "coastal_smiling_woman.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "MASTER_IMAGE"
    }
  },
  "82": {
    "inputs": {
      "upscale_method": "lanczos",
      "largest_size": 640,
      "image": [
        "74",
        0
      ]
    },
    "class_type": "ImageScaleToMaxDimension",
    "_meta": {
      "title": "ImageScaleToMaxDimension"
    }
  },
  "116": {
    "inputs": {
      "value": "A cinematic medium shot of a beautiful young woman with fair skin and a joyful, radiant smile, looking back over her shoulder. She has voluminous, curly auburn hair styled in a loose, windblown updo. She is standing on a rugged, rocky coastline overlooking a sun-drenched ocean. She wears a vintage, long-sleeved, high-collared dress in an off-white, crinkled fabric with delicate smocking on the bodice and a simple brown sash at her waist. In the background, the ocean sparkles brightly under the sun, and a majestic tall ship with full sails is visible in the distance. The scene is illuminated by the warm, golden light of the late afternoon, creating a soft, romantic, and nostalgic atmosphere with a shallow depth of field that keeps the woman in sharp focus."
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "MASTER_PROMPT"
    }
  },
  "118": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "119": {
    "inputs": {
      "vae_name": "qwen_image_layered_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "120": {
    "inputs": {
      "text": "",
      "clip": [
        "118",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "121": {
    "inputs": {
      "conditioning": [
        "120",
        0
      ],
      "latent": [
        "125",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "122": {
    "inputs": {
      "conditioning": [
        "127",
        0
      ],
      "latent": [
        "125",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "123": {
    "inputs": {
      "shift": 1,
      "model": [
        "132",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "124": {
    "inputs": {
      "dim": "t",
      "slice_size": 1,
      "samples": [
        "128",
        0
      ]
    },
    "class_type": "LatentCutToBatch",
    "_meta": {
      "title": "LatentCutToBatch"
    }
  },
  "125": {
    "inputs": {
      "pixels": [
        "82",
        0
      ],
      "vae": [
        "119",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "126": {
    "inputs": {
      "samples": [
        "124",
        0
      ],
      "vae": [
        "119",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "127": {
    "inputs": {
      "text": [
        "116",
        0
      ],
      "clip": [
        "118",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "128": {
    "inputs": {
      "seed": 657641993490688,
      "steps": 20,
      "cfg": 2.5,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "123",
        0
      ],
      "positive": [
        "122",
        0
      ],
      "negative": [
        "121",
        0
      ],
      "latent_image": [
        "130",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "129": {
    "inputs": {
      "image": [
        "82",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "130": {
    "inputs": {
      "width": [
        "129",
        0
      ],
      "height": [
        "129",
        1
      ],
      "layers": 2,
      "batch_size": 1
    },
    "class_type": "EmptyQwenImageLayeredLatentImage",
    "_meta": {
      "title": "Empty Qwen Image Layered Latent"
    }
  },
  "132": {
    "inputs": {
      "unet_name": "qwen-image-layered-Q6_K.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "133": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "MASTER_FILENAME"
    }
  }
}